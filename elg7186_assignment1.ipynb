{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELG7186 - fall 2022 - Assignment 1\n",
    "## Due: <strong>Wednesday Oct. 12<sup>th</sup> 2022 -- 11:59pm</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this assignment is to gain some experience working with the tools you will use throughout the course. You will learn:\n",
    "- The basics of data loading and preparation\n",
    "- Classification using the k-NN algorithm\n",
    "- Classification using a Support Vector Machine (SVM)\n",
    "- Calculation of metrics to assess the performance of your model\n",
    "\n",
    "### Submission Details\n",
    "Submit your Jupyter notebook .ipynb file using Brightspace. Do not include any other files or images as they will not be reviewed.\n",
    "<p>\n",
    "<strong>Make certain that you run all the cells in the notebook you will submit</strong> or you will loose marks.\n",
    "</p>\n",
    "<ul>\n",
    "<li>You can submit multiple times, but only the most recent submission will be saved</li>\n",
    "<li>Do not wait until the last minute to submit in case you have an unexpected issue</li>\n",
    "<li>Review the late policy in the syllabus</li>\n",
    "<li><strong>You must submit your own work</strong> and abide by the University of Ottawa policy on plagiarism and fraud</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Dataset Preparation\n",
    "To complete the assignment you will need to download the Cifar10 dataset and devise an appropriate training set split. You may acquire the dataset using the method of your choice. Note that some sources e.g. sklearn have reduced the samples to only 1797 (this could negatively affect your results). If you use the full dataset, you are free to sample from the dataset to reduce the overal training samples. The overall accuracy is less important than your  observations and comparisons. For example classifying the full 10,000 test images might take approximately 15 minutes using k-NN.\n",
    "\n",
    "In this section:\n",
    "<ul>\n",
    "<li>Download the dataset as described above</li>\n",
    "<li>Divide the raw data into appropriate training and test sets for both the images and corresponding labels for use with the subsequent parts of the assignment.</li>\n",
    "<li>Visualize five samples of each class by plotting a grid using the matplotlib library.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your dataset here and display samples here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. k-NN Classifier (2 Marks)\n",
    "For this section you will implement a simple kNN Classifier on the Cifar10 dataset. To do this you will need to perform the following steps:\n",
    "- Create a k-NN class. Your class must contain a method that returns predictions for your test set.\n",
    "- Provide a suitable distance metric that you will use to calculate the nearest neightbours. You may choose the distance metric you believe is most suitable.\n",
    "- Calculate the k nearest neighbours and make predictions.\n",
    "- Choose the a value for _k_ that results in the highest accuracy on your test set. Show how you found this value.\n",
    "\n",
    "When your classifier is working:\n",
    "- Use sklearn to calculate accuracy and plot a confusion matrix using your predictions.\n",
    "- Provide a brief discussion of your results\n",
    "\n",
    "### Bonus:\n",
    "\n",
    "When you compute the distance metric you can acheive better performance if you vectorize the computation instead of using for loops to iterate through the values. You can earn __0.5 bonus marks__ if you only need one loop, or __1 bonus mark__ if you can omit for loops for a fully vectorized distance calculation (a maximum of 1 bonus mark is available).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your KNN class here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Logistic Regression (3 Marks)\n",
    "\n",
    "For this section you will perform binary classification using logistic regression. Just as in Part 1. you will use the Cifar10 dataset, however to obtain a result for each class using logistic regression you will need to use a One-vs-Rest (OvR) approach to acheive multi-class classification.\n",
    "\n",
    "Using ```LogisticRegression()``` in sklearn, write a function to execute the OvR strategy for the Cifar10 classes. Do not use the built-in ```OneVsResClassifier()``` method. You will need to follow these basic steps:\n",
    "- Train a binary classifier for each class, where the target class is a \"positive\" results and the combination of the remaining classes are \"negative\". For Cifar10 you will need 10 models.\n",
    "- For each test sample compute the probabilities for each model\n",
    "- Select the argmax of the probabilities to obtain the predicted class\n",
    "\n",
    "Collect your predictions from the test set and compute the accuracy score and plot a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your logistic regression code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Support Vector Machine (SVM) Classification (4 Marks)\n",
    "\n",
    "In Part 3. you will use Scikit-learn to perform classification, again on the Cifar10 dataset. You can use the built in SVM library for classification. As with logistic regression, SVM is designed for binary classification. However, in this case Scikit-learn will handle the OvR models behind the scenes.\n",
    "\n",
    "Your task is to compare different modes of the SVM and determine the best performer. \n",
    "\n",
    "Create an SVM baseline using the <code>LinearSVC()</code> function. Make sure to use the primal solution and use \"ovr\" for multiclass Calculate the accuracy score for comparison.\n",
    "\n",
    "Next you will explore the effect of the cost parameter on the accuracy.\n",
    "    <ul>\n",
    "    <li>Run the classification with a range of C values For example: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000 ]</li>\n",
    "    <li>Plot the results as an accuracy vs. C-parameter curve on a logarithmic scale.</li>\n",
    "    </ul>\n",
    "\n",
    "Add a regularization term.\n",
    "    <ul>\n",
    "    <li>Rerun the above experiment, but this time use L1 regularization.</li>\n",
    "    <li>Again, plot the results as an accuracy vs. C-parameter curve on a logarithmic scale.</li>\n",
    "    </ul>\n",
    "\n",
    "For the final experiment you will use the ```SVC()``` function to run the classifer with a kernel.\n",
    "    <ul>\n",
    "    <li>Use a radial basis function when training a new model</li>\n",
    "    <li>Find the optimal combination of values for the cost and gamma parameters. Use the following values in your loop:<br/>\n",
    "        <div style=\"margin-left:40px\"><code>\n",
    "        for cost in [0.01, 0.1, 1, 10, 100]:<br/>\n",
    "        &emsp;for gamma in [0.01, 0.1, 1, 10, 100]:\n",
    "        </code></div>\n",
    "    </li>\n",
    "    <li>Again, plot the results as an accuracy vs. C-parameter curve on a logarithmic scale.</li>\n",
    "    </ul>\n",
    "\n",
    "\n",
    "Choose the model with the highest accuracy and plot the confusion matrix. In your discussion explain the results of your experiments and the reason for increased performance from the baseline (if any). Comment on the effect of the cost-paramenter and the L1 penalty on accuracy as well as any overfitting you observed. Discuss the confusion matrix of the model accuracy and provide some reasons for high-values found off the main diagonal.\n",
    "\n",
    "### Bonus Mark\n",
    "Instead of using raw pixel values compute an alternate feature representation for your dataset and re-run train the model. Compare the accuracy of the model using the new feature representation with the model trained with pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your SVM experiments here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Write a Conclusion (1 Mark)\n",
    "\n",
    "Write a conclusion comparing the results from each part of the assignment. Comment on the suitability of each method for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Write your conclusion here -->"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f29ff496c4975542d1ca3f875208135529fae10fbd9e5dbdc796e5f81fffc359"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('synthesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}